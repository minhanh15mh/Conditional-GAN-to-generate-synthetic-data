{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMjk3WKzKZhf0iZ9II4po0h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BAF1JUMUe-Ed"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from keras import layers\n","import tensorflow as tf\n","import keras\n","from tensorflow import keras\n","import pickle"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzCIyyT7fPBE","executionInfo":{"status":"ok","timestamp":1660986974524,"user_tz":-420,"elapsed":22804,"user":{"displayName":"Hạnh Nguyễn","userId":"10749883247945940465"}},"outputId":"12d7ef72-f1f2-4692-8a53-8de4ca377bf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Load data for training GAN"],"metadata":{"id":"YusNz9veXMYw"}},{"cell_type":"code","source":["wafer_map = pd.read_pickle('/content/drive/MyDrive/Capstone_programming/Data_final/wafer_map_for_GAN.pkl')\n","wafer_label = pd.read_pickle('/content/drive/MyDrive/Capstone_programming/Data_final/wafer_label_for_GAN.pkl')"],"metadata":{"id":"8lRcuTopfWO2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Median Filter"],"metadata":{"id":"AcQGoWpl6RMe"}},{"cell_type":"code","source":["#median function\n","from skimage.filters.rank import median\n","from skimage.morphology import disk\n","def median_img(x):\n","  img_out = median(x,disk(1.5))\n","  return img_out\n"],"metadata":{"id":"U4OEyEGxx24M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["median_image = []\n","median_label = []\n","\n","for i in range(len(x)): \n","      median_image.append(median_img(x[i]))\n","      median_label.append(y[i])\n","    \n","median_image = np.array(median_image)\n","median_label = np.array(median_label)    "],"metadata":{"id":"DAoyuaxQv1v1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## cGAN model"],"metadata":{"id":"qIt0dc838itY"}},{"cell_type":"markdown","source":["### Set up"],"metadata":{"id":"pzhwX96N833W"}},{"cell_type":"code","source":["batch_size = 32\n","num_channels = 1\n","num_classes = 8\n","image_size = 28\n","latent_dim = 128"],"metadata":{"id":"Y-7Rn7M18lpN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generator_in_channels = latent_dim + num_classes\n","discriminator_in_channels = num_channels + num_classes\n","print(generator_in_channels, discriminator_in_channels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5R-oNozp8xd6","executionInfo":{"status":"ok","timestamp":1657985154298,"user_tz":-420,"elapsed":2,"user":{"displayName":"Hạnh Nguyễn","userId":"10749883247945940465"}},"outputId":"7ec14c32-35d4-4163-c46f-fd3f94f6d75d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["136 9\n"]}]},{"cell_type":"code","source":["gan_wafer = median_image\n","gan_labels = median_label\n","\n","# Scale the pixel values to [0, 1] range, add a channel dimension to\n","# the images, and one-hot encode the labels.\n","gan_wafer = gan_wafer.astype(\"float32\") \n","gan_wafer *= 127.5\n","gan_wafer = gan_wafer/255\n","gan_wafer = np.reshape(gan_wafer, (-1, 28, 28, 1))\n","gan_labels = keras.utils.to_categorical(gan_labels, num_classes )\n","\n","# Create tf.data.Dataset.\n","dataset = tf.data.Dataset.from_tensor_slices((gan_wafer, gan_labels))\n","dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n","\n","print(f\"Shape of training images: {gan_wafer.shape}\")\n","print(f\"Shape of training labels: {gan_labels.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8s1u9KDW9Gqu","executionInfo":{"status":"ok","timestamp":1657985161658,"user_tz":-420,"elapsed":457,"user":{"displayName":"Hạnh Nguyễn","userId":"10749883247945940465"}},"outputId":"6a8fd71d-efcd-4b61-edb1-118c6906d30e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of training images: (3675, 28, 28, 1)\n","Shape of training labels: (3675, 8)\n"]}]},{"cell_type":"markdown","source":["### GAN architecture"],"metadata":{"id":"2X_e5CU78-Nk"}},{"cell_type":"code","source":["discriminator = keras.Sequential(\n","    [\n","        keras.layers.InputLayer((28, 28, discriminator_in_channels)),\n","        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.BatchNormalization(),\n","        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.BatchNormalization(),\n","        layers.GlobalMaxPooling2D(),\n","        layers.Dense(1,activation=\"sigmoid\"),\n","    ],\n","    name=\"discriminator\",\n",")\n","\n","# Create the generator.\n","generator = keras.Sequential(\n","    [\n","        keras.layers.InputLayer((generator_in_channels,)),\n","        # We want to generate 128 + num_classes coefficients to reshape into a\n","        # 7x7x(128 + num_classes) map.\n","        layers.Dense(7 * 7 * generator_in_channels),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Reshape((7, 7, generator_in_channels)),\n","        layers.Conv2DTranspose(256, (4, 4),strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.BatchNormalization(),\n","        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.BatchNormalization(),\n","        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"tanh\"),\n","    ],\n","    name=\"generator\",\n",")\n"],"metadata":{"id":"bfIUrjvt88q1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GAN training"],"metadata":{"id":"cXJ9rqJT9xOh"}},{"cell_type":"code","source":["class ConditionalGAN(keras.Model):\n","    def __init__(self, discriminator, generator, latent_dim):\n","        super(ConditionalGAN, self).__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n","        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [self.gen_loss_tracker, self.disc_loss_tracker]\n","\n","    def compile(self, d_optimizer, g_optimizer, loss_fn):\n","        super(ConditionalGAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.loss_fn = loss_fn\n","\n","    def train_step(self, data):\n","        # Unpack the data.\n","        real_images, one_hot_labels = data\n","\n","        # Add dummy dimensions to the labels so that they can be concatenated with\n","        # the images. This is for the discriminator.\n","        image_one_hot_labels = one_hot_labels[:, :, None, None]\n","        image_one_hot_labels = tf.repeat(\n","            image_one_hot_labels, repeats=[image_size * image_size]\n","        )\n","        image_one_hot_labels = tf.reshape(\n","            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n","        )\n","\n","        # Sample random points in the latent space and concatenate the labels.\n","        # This is for the generator.\n","        batch_size = tf.shape(real_images)[0]\n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        random_vector_labels = tf.concat(\n","            [random_latent_vectors, one_hot_labels], axis=1\n","        )\n","\n","        # Decode the noise (guided by labels) to fake images.\n","        generated_images = self.generator(random_vector_labels)\n","\n","        # Combine them with real images. Note that we are concatenating the labels\n","        # with these images here.\n","        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n","        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n","        combined_images = tf.concat(\n","            [fake_image_and_labels, real_image_and_labels], axis=0\n","        )\n","\n","        # Assemble labels discriminating real from fake images.\n","        labels = tf.concat(\n","            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n","        )\n","\n","        # Train the discriminator.\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(combined_images)\n","            d_loss = self.loss_fn(labels, predictions)\n","        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n","        self.d_optimizer.apply_gradients(\n","            zip(grads, self.discriminator.trainable_weights)\n","        )\n","\n","        # Sample random points in the latent space.\n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        random_vector_labels = tf.concat(\n","            [random_latent_vectors, one_hot_labels], axis=1\n","        )\n","\n","        # Assemble labels that say \"all real images\".\n","        misleading_labels = tf.zeros((batch_size, 1))\n","\n","        # Train the generator (note that we should *not* update the weights\n","        # of the discriminator)!\n","        with tf.GradientTape() as tape:\n","            fake_images = self.generator(random_vector_labels)\n","            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n","            predictions = self.discriminator(fake_image_and_labels)\n","            g_loss = self.loss_fn(misleading_labels, predictions)\n","        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n","        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n","\n","        # Monitor loss.\n","        self.gen_loss_tracker.update_state(g_loss)\n","        self.disc_loss_tracker.update_state(d_loss)\n","        return {\n","            \"g_loss\": self.gen_loss_tracker.result(),\n","            \"d_loss\": self.disc_loss_tracker.result(),\n","        }"],"metadata":{"id":"sXCL3R_69wpC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cond_gan = ConditionalGAN(\n","    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",")\n","cond_gan.compile(\n","    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002,beta_1=0.5),\n","    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002,beta_1=0.5),\n","    loss_fn=keras.losses.BinaryCrossentropy(from_logits=False),\n",")\n","\n","cond_gan.fit(dataset, epochs=150)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGNn6xeU94Re","executionInfo":{"status":"ok","timestamp":1657985538914,"user_tz":-420,"elapsed":355815,"user":{"displayName":"Hạnh Nguyễn","userId":"10749883247945940465"}},"outputId":"94e57dd4-2a81-4a8d-b45f-0580247c85f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","115/115 [==============================] - 5s 19ms/step - g_loss: 0.8192 - d_loss: 0.6372\n","Epoch 2/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.8803 - d_loss: 0.5774\n","Epoch 3/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.7633 - d_loss: 0.6432\n","Epoch 4/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.7738 - d_loss: 0.6418\n","Epoch 5/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.8062 - d_loss: 0.6286\n","Epoch 6/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.8223 - d_loss: 0.6281\n","Epoch 7/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.8155 - d_loss: 0.6331\n","Epoch 8/150\n","115/115 [==============================] - 2s 19ms/step - g_loss: 0.8094 - d_loss: 0.6185\n","Epoch 9/150\n","115/115 [==============================] - 2s 20ms/step - g_loss: 0.8341 - d_loss: 0.6357\n","Epoch 10/150\n","115/115 [==============================] - 2s 20ms/step - g_loss: 0.8200 - d_loss: 0.6173\n","Epoch 11/150\n","115/115 [==============================] - 3s 22ms/step - g_loss: 0.8254 - d_loss: 0.6051\n","Epoch 12/150\n","115/115 [==============================] - 2s 20ms/step - g_loss: 0.8546 - d_loss: 0.6043\n","Epoch 13/150\n","115/115 [==============================] - 2s 19ms/step - g_loss: 0.8737 - d_loss: 0.5998\n","Epoch 14/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.8842 - d_loss: 0.5759\n","Epoch 15/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.8835 - d_loss: 0.5759\n","Epoch 16/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.9122 - d_loss: 0.5627\n","Epoch 17/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.9276 - d_loss: 0.5545\n","Epoch 18/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.9307 - d_loss: 0.5583\n","Epoch 19/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.9292 - d_loss: 0.5606\n","Epoch 20/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.9650 - d_loss: 0.5513\n","Epoch 21/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.9583 - d_loss: 0.5370\n","Epoch 22/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.9948 - d_loss: 0.5359\n","Epoch 23/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 0.9845 - d_loss: 0.5156\n","Epoch 24/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.0103 - d_loss: 0.5199\n","Epoch 25/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.0423 - d_loss: 0.5152\n","Epoch 26/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.0568 - d_loss: 0.5108\n","Epoch 27/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.0372 - d_loss: 0.4978\n","Epoch 28/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.0611 - d_loss: 0.5025\n","Epoch 29/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.0897 - d_loss: 0.4866\n","Epoch 30/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.1161 - d_loss: 0.4819\n","Epoch 31/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.1305 - d_loss: 0.4727\n","Epoch 32/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.1375 - d_loss: 0.4782\n","Epoch 33/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.1145 - d_loss: 0.4604\n","Epoch 34/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.1413 - d_loss: 0.4574\n","Epoch 35/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.2259 - d_loss: 0.4551\n","Epoch 36/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.1679 - d_loss: 0.4540\n","Epoch 37/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.2151 - d_loss: 0.4529\n","Epoch 38/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.1864 - d_loss: 0.4160\n","Epoch 39/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.2372 - d_loss: 0.4280\n","Epoch 40/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.2364 - d_loss: 0.4071\n","Epoch 41/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.2571 - d_loss: 0.4250\n","Epoch 42/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.2617 - d_loss: 0.4212\n","Epoch 43/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.2642 - d_loss: 0.4006\n","Epoch 44/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.3246 - d_loss: 0.4212\n","Epoch 45/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.3106 - d_loss: 0.4002\n","Epoch 46/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.3031 - d_loss: 0.3965\n","Epoch 47/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.3548 - d_loss: 0.4034\n","Epoch 48/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.3509 - d_loss: 0.3961\n","Epoch 49/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.3874 - d_loss: 0.3686\n","Epoch 50/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.3532 - d_loss: 0.4040\n","Epoch 51/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.4086 - d_loss: 0.3741\n","Epoch 52/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.3875 - d_loss: 0.3876\n","Epoch 53/150\n","115/115 [==============================] - 2s 19ms/step - g_loss: 1.4156 - d_loss: 0.3583\n","Epoch 54/150\n","115/115 [==============================] - 2s 20ms/step - g_loss: 1.4337 - d_loss: 0.3962\n","Epoch 55/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.3807 - d_loss: 0.3896\n","Epoch 56/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.4389 - d_loss: 0.3788\n","Epoch 57/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.4743 - d_loss: 0.3699\n","Epoch 58/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.4598 - d_loss: 0.3553\n","Epoch 59/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.4960 - d_loss: 0.3745\n","Epoch 60/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.4693 - d_loss: 0.3502\n","Epoch 61/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.4725 - d_loss: 0.3653\n","Epoch 62/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.5013 - d_loss: 0.3527\n","Epoch 63/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.5229 - d_loss: 0.3600\n","Epoch 64/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.5470 - d_loss: 0.3444\n","Epoch 65/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.5112 - d_loss: 0.3388\n","Epoch 66/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.5417 - d_loss: 0.3741\n","Epoch 67/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.5423 - d_loss: 0.3402\n","Epoch 68/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.5721 - d_loss: 0.3487\n","Epoch 69/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.5924 - d_loss: 0.3419\n","Epoch 70/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.5810 - d_loss: 0.3343\n","Epoch 71/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.6039 - d_loss: 0.3428\n","Epoch 72/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.5867 - d_loss: 0.3206\n","Epoch 73/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.6338 - d_loss: 0.3323\n","Epoch 74/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.6105 - d_loss: 0.3357\n","Epoch 75/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.6077 - d_loss: 0.3354\n","Epoch 76/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.6586 - d_loss: 0.3147\n","Epoch 77/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.6441 - d_loss: 0.3150\n","Epoch 78/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.6840 - d_loss: 0.2907\n","Epoch 79/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.7063 - d_loss: 0.3435\n","Epoch 80/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.7130 - d_loss: 0.3065\n","Epoch 81/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.7579 - d_loss: 0.3621\n","Epoch 82/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.7108 - d_loss: 0.3125\n","Epoch 83/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.7770 - d_loss: 0.2989\n","Epoch 84/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.7263 - d_loss: 0.3003\n","Epoch 85/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.8001 - d_loss: 0.3263\n","Epoch 86/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.7811 - d_loss: 0.2760\n","Epoch 87/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.7894 - d_loss: 0.2992\n","Epoch 88/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.7316 - d_loss: 0.3147\n","Epoch 89/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.7929 - d_loss: 0.2809\n","Epoch 90/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.8190 - d_loss: 0.2889\n","Epoch 91/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.8232 - d_loss: 0.3089\n","Epoch 92/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.8267 - d_loss: 0.2691\n","Epoch 93/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.8632 - d_loss: 0.3008\n","Epoch 94/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.8410 - d_loss: 0.2821\n","Epoch 95/150\n","115/115 [==============================] - 2s 21ms/step - g_loss: 1.8101 - d_loss: 0.2882\n","Epoch 96/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.8605 - d_loss: 0.2900\n","Epoch 97/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.8834 - d_loss: 0.2737\n","Epoch 98/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.9270 - d_loss: 0.2678\n","Epoch 99/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.8604 - d_loss: 0.2789\n","Epoch 100/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.8714 - d_loss: 0.2662\n","Epoch 101/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.9061 - d_loss: 0.2685\n","Epoch 102/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.9131 - d_loss: 0.3080\n","Epoch 103/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.9194 - d_loss: 0.2671\n","Epoch 104/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.9517 - d_loss: 0.2542\n","Epoch 105/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.9526 - d_loss: 0.2702\n","Epoch 106/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.9302 - d_loss: 0.2357\n","Epoch 107/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.9766 - d_loss: 0.2910\n","Epoch 108/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.9879 - d_loss: 0.2877\n","Epoch 109/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.9672 - d_loss: 0.2707\n","Epoch 110/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.0994 - d_loss: 0.2546\n","Epoch 111/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 1.9610 - d_loss: 0.2380\n","Epoch 112/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.0264 - d_loss: 0.2596\n","Epoch 113/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.0069 - d_loss: 0.2816\n","Epoch 114/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.0319 - d_loss: 0.2593\n","Epoch 115/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.0464 - d_loss: 0.2771\n","Epoch 116/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.0730 - d_loss: 0.2510\n","Epoch 117/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.0692 - d_loss: 0.2447\n","Epoch 118/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.0994 - d_loss: 0.2630\n","Epoch 119/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.1544 - d_loss: 0.2564\n","Epoch 120/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.0042 - d_loss: 0.2429\n","Epoch 121/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.1175 - d_loss: 0.2570\n","Epoch 122/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.1139 - d_loss: 0.2536\n","Epoch 123/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.1496 - d_loss: 0.2492\n","Epoch 124/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.1331 - d_loss: 0.2907\n","Epoch 125/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.1194 - d_loss: 0.2292\n","Epoch 126/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.1715 - d_loss: 0.2754\n","Epoch 127/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.1352 - d_loss: 0.2663\n","Epoch 128/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.1972 - d_loss: 0.2216\n","Epoch 129/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.2397 - d_loss: 0.2359\n","Epoch 130/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.1367 - d_loss: 0.2172\n","Epoch 131/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.2299 - d_loss: 0.2333\n","Epoch 132/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.1852 - d_loss: 0.2304\n","Epoch 133/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.1581 - d_loss: 0.2640\n","Epoch 134/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.2187 - d_loss: 0.2593\n","Epoch 135/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.1704 - d_loss: 0.2394\n","Epoch 136/150\n","115/115 [==============================] - 2s 20ms/step - g_loss: 2.2047 - d_loss: 0.2207\n","Epoch 137/150\n","115/115 [==============================] - 2s 19ms/step - g_loss: 2.3141 - d_loss: 0.2504\n","Epoch 138/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.2311 - d_loss: 0.2334\n","Epoch 139/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.2780 - d_loss: 0.2690\n","Epoch 140/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.2246 - d_loss: 0.2526\n","Epoch 141/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.2433 - d_loss: 0.2242\n","Epoch 142/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.3003 - d_loss: 0.2188\n","Epoch 143/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.3582 - d_loss: 0.2391\n","Epoch 144/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.4407 - d_loss: 0.2404\n","Epoch 145/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.3670 - d_loss: 0.2038\n","Epoch 146/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.3854 - d_loss: 0.2584\n","Epoch 147/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.3148 - d_loss: 0.2469\n","Epoch 148/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.2539 - d_loss: 0.2711\n","Epoch 149/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.3409 - d_loss: 0.2044\n","Epoch 150/150\n","115/115 [==============================] - 2s 18ms/step - g_loss: 2.3461 - d_loss: 0.1955\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2bbe228a90>"]},"metadata":{},"execution_count":105}]},{"cell_type":"markdown","source":["## Using GAN to balance"],"metadata":{"id":"5xI0T6C5WjHD"}},{"cell_type":"code","source":["def interpolate_image(num_label,num_interpolation,gan_generator):\n","    # Sample noise for the interpolation.\n","    interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n","    interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n","    interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n","    # Convert the start and end labels to one-hot encoded vectors.\n","    label = keras.utils.to_categorical([num_label], num_classes)\n","    label = tf.cast(label, tf.float32)\n","\n","    # Calculate the interpolation vector between the two labels.\n","    percent_label = tf.linspace(0, 1, num_interpolation)[:, None]\n","    percent_label = tf.cast(percent_label, tf.float32)\n","    interpolation_labels = (\n","        label * (1 - percent_label +  percent_label )\n","        )\n","\n","    # Combine the noise and the labels and run inference with the generator.\n","    noise_and_labels = tf.concat([interpolation_noise,  interpolation_labels], 1)\n","    fake_image = gan_generator.predict(noise_and_labels)\n","    return fake_image,  interpolation_labels "],"metadata":{"id":"KMh-vptZWfA3"},"execution_count":null,"outputs":[]}]}